"""
Script de validaci√≥n integral para datos del pipeline de seguridad.

Valida:
- Integridad estructural (columnas requeridas)
- Valores nulos y duplicados
- Distribuci√≥n de clases (desbalance)
- Calidad del c√≥digo fuente
- Longitud y caracter√≠sticas del c√≥digo
"""

import pandas as pd
import sys
from pathlib import Path
import numpy as np
from collections import Counter


def validate_dataset(dataset_path: str):
    """Validaci√≥n completa del dataset."""
    
    print("üîç Validaci√≥n del Dataset")
    print("=" * 70)
    
    # 1. Verificar existencia
    path = Path(dataset_path)
    if not path.exists():
        print(f"‚ùå Error: {dataset_path} no encontrado")
        return False
    
    print(f"üìÇ Archivo: {dataset_path}")
    print(f"üì¶ Tama√±o: {path.stat().st_size / 1024**2:.2f} MB\n")
    
    # 2. Cargar dataset
    try:
        df = pd.read_csv(dataset_path, low_memory=False)
        print(f"‚úÖ Dataset cargado: {len(df)} filas, {len(df.columns)} columnas\n")
    except Exception as e:
        print(f"‚ùå Error al cargar dataset: {e}")
        return False
    
    all_valid = True
    
    # 3. Validar estructura
    print("üìã Validaci√≥n de Estructura")
    print("-" * 70)
    
    required_columns = {'id', 'label', 'language', 'code'}
    missing_columns = required_columns - set(df.columns)
    
    if missing_columns:
        print(f"‚ùå Faltan columnas requeridas: {missing_columns}")
        all_valid = False
    else:
        print(f"‚úÖ Todas las columnas requeridas presentes: {required_columns}")
    
    print(f"\nColumnas actuales: {list(df.columns)}\n")
    
    # 4. Validar valores nulos
    print("üîé Validaci√≥n de Valores Nulos")
    print("-" * 70)
    
    null_counts = df.isnull().sum()
    has_nulls = False
    
    for col in required_columns:
        if col in df.columns:
            null_count = null_counts[col]
            null_pct = (null_count / len(df)) * 100
            
            if null_count > 0:
                print(f"‚ö†Ô∏è  {col}: {null_count} nulos ({null_pct:.2f}%)")
                has_nulls = True
                all_valid = False
            else:
                print(f"‚úÖ {col}: Sin valores nulos")
    
    if not has_nulls:
        print("‚úÖ No hay valores nulos en columnas cr√≠ticas")
    
    print()
    
    # 5. Validar etiquetas
    print("üè∑Ô∏è  Validaci√≥n de Etiquetas")
    print("-" * 70)
    
    if 'label' in df.columns:
        label_counts = df['label'].value_counts()
        print("Distribuci√≥n de clases:")
        
        for label, count in label_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  - {label}: {count} ({percentage:.2f}%)")
        
        # Detectar desbalance
        if len(label_counts) >= 2:
            max_class = label_counts.max()
            min_class = label_counts.min()
            imbalance_ratio = max_class / min_class
            
            print(f"\nüìä Ratio de desbalance: {imbalance_ratio:.2f}:1")
            
            if imbalance_ratio > 10:
                print("‚ö†Ô∏è  ADVERTENCIA: Desbalance severo de clases")
                print("   Recomendaci√≥n: Usar class_weight='balanced' en el modelo")
            elif imbalance_ratio > 3:
                print("‚ö†Ô∏è  Desbalance moderado de clases")
        
        # Validar valores v√°lidos
        valid_labels = {'vulnerable', 'seguro'}
        invalid_labels = set(df['label'].unique()) - valid_labels
        
        if invalid_labels:
            print(f"\n‚ùå Etiquetas inv√°lidas detectadas: {invalid_labels}")
            all_valid = False
        else:
            print("\n‚úÖ Todas las etiquetas son v√°lidas")
    
    print()
    
    # 6. Validar lenguajes
    print("üó£Ô∏è  Validaci√≥n de Lenguajes")
    print("-" * 70)
    
    if 'language' in df.columns:
        lang_counts = df['language'].value_counts()
        print("Lenguajes detectados:")
        
        for lang, count in lang_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  - {lang}: {count} ({percentage:.2f}%)")
        
        print(f"\n‚úÖ Total de lenguajes: {len(lang_counts)}")
    
    print()
    
    # 7. Validar c√≥digo
    print("üíª Validaci√≥n de C√≥digo Fuente")
    print("-" * 70)
    
    if 'code' in df.columns:
        # Longitud del c√≥digo
        code_lengths = df['code'].astype(str).str.len()
        
        print("Estad√≠sticas de longitud:")
        print(f"  - M√≠nimo: {code_lengths.min()} caracteres")
        print(f"  - M√°ximo: {code_lengths.max()} caracteres")
        print(f"  - Promedio: {code_lengths.mean():.0f} caracteres")
        print(f"  - Mediana: {code_lengths.median():.0f} caracteres")
        
        # Detectar c√≥digo muy corto (posiblemente inv√°lido)
        too_short = (code_lengths < 20).sum()
        if too_short > 0:
            print(f"\n‚ö†Ô∏è  {too_short} registros con c√≥digo muy corto (<20 chars)")
        
        # Detectar c√≥digo muy largo (posiblemente problem√°tico)
        too_long = (code_lengths > 10000).sum()
        if too_long > 0:
            print(f"‚ö†Ô∏è  {too_long} registros con c√≥digo muy largo (>10k chars)")
        
        # L√≠neas de c√≥digo
        df['num_lines'] = df['code'].astype(str).str.count('\n') + 1
        print(f"\nL√≠neas de c√≥digo:")
        print(f"  - Promedio: {df['num_lines'].mean():.1f} l√≠neas")
        print(f"  - Mediana: {df['num_lines'].median():.1f} l√≠neas")
        
        print("\n‚úÖ Validaci√≥n de c√≥digo completada")
    
    print()
    
    # 8. Validar duplicados
    print("üîÑ Validaci√≥n de Duplicados")
    print("-" * 70)
    
    # Duplicados por ID
    if 'id' in df.columns:
        duplicated_ids = df['id'].duplicated().sum()
        if duplicated_ids > 0:
            print(f"‚ö†Ô∏è  {duplicated_ids} IDs duplicados")
            all_valid = False
        else:
            print("‚úÖ No hay IDs duplicados")
    
    # Duplicados de c√≥digo
    if 'code' in df.columns:
        duplicated_code = df['code'].duplicated().sum()
        if duplicated_code > 0:
            dup_pct = (duplicated_code / len(df)) * 100
            print(f"‚ö†Ô∏è  {duplicated_code} c√≥digos duplicados ({dup_pct:.2f}%)")
        else:
            print("‚úÖ No hay c√≥digos duplicados")
    
    print()
    
    # 9. Resumen final
    print("=" * 70)
    if all_valid:
        print("‚úÖ DATASET V√ÅLIDO - Listo para entrenamiento")
        return True
    else:
        print("‚ö†Ô∏è  DATASET CON ADVERTENCIAS - Revisar problemas detectados")
        return False


def generate_statistics_report(dataset_path: str, output_path: str = "data/validation_report.txt"):
    """Genera un reporte detallado de estad√≠sticas."""
    
    df = pd.read_csv(dataset_path, low_memory=False)
    
    report_lines = []
    report_lines.append("=" * 70)
    report_lines.append("REPORTE DE VALIDACI√ìN DEL DATASET")
    report_lines.append("=" * 70)
    report_lines.append(f"\nArchivo: {dataset_path}")
    report_lines.append(f"Fecha: {pd.Timestamp.now()}")
    report_lines.append(f"\nTotal de registros: {len(df)}")
    report_lines.append(f"Columnas: {list(df.columns)}")
    
    if 'label' in df.columns:
        report_lines.append("\n--- Distribuci√≥n de Clases ---")
        for label, count in df['label'].value_counts().items():
            pct = (count / len(df)) * 100
            report_lines.append(f"{label}: {count} ({pct:.2f}%)")
    
    if 'language' in df.columns:
        report_lines.append("\n--- Distribuci√≥n de Lenguajes ---")
        for lang, count in df['language'].value_counts().items():
            pct = (count / len(df)) * 100
            report_lines.append(f"{lang}: {count} ({pct:.2f}%)")
    
    report = "\n".join(report_lines)
    
    # Guardar reporte
    output = Path(output_path)
    output.parent.mkdir(parents=True, exist_ok=True)
    output.write_text(report, encoding='utf-8')
    
    print(f"üìÑ Reporte guardado en: {output_path}")
    
    return report


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Valida el dataset del pipeline")
    parser.add_argument("dataset", help="Ruta al archivo CSV del dataset")
    parser.add_argument("--report", action="store_true", 
                       help="Generar reporte detallado en archivo")
    
    args = parser.parse_args()
    
    # Validar
    is_valid = validate_dataset(args.dataset)
    
    # Generar reporte si se solicita
    if args.report:
        generate_statistics_report(args.dataset)
    
    # Exit code
    sys.exit(0 if is_valid else 1)
